# -*- coding: utf-8 -*-
"""4580_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WYTpIXn4KaKs92LFdmhaTQK1PsfHI5Rf
"""

import numpy as np
# General class for the Queries through the Queues
class Entity(object):

    # Initialize an Entity
    def __init__(self, arrival_time_at_system):
        self.arrival_time_at_system = arrival_time_at_system
        # arbitrary numbers, small/medium/large number of prefill tokens
        self.p_token = np.random.choice([10, 100, 500])
        # based on project description, B_i is Geometric(1/16)
        self.b_token = np.random.geometric(0.0625)

        self.arrival_time_at_queue = -1  # Time it enters the processing queue
        self.start_processing_time = -1  # Time processing begins
        self.completion_time = -1        # Time processing finishes

    # Print an Entity
    def __repr__(self):
        arr_q_str = f"{self.arrival_time_at_queue:.2f}" if self.arrival_time_at_queue != -1 else "N/A"
        start_proc_str = f"{self.start_processing_time:.2f}" if self.start_processing_time != -1 else "N/A"
        comp_str = f"{self.completion_time:.2f}" if self.completion_time != -1 else "N/A"
        return (f"Entity(arr_sys={self.arrival_time_at_system:.2f}, p={self.p_token}, "
                f"b={self.b_token}, arr_q={arr_q_str}, "
                f"start_proc={start_proc_str}, comp={comp_str})")

# General class for the queues themselves
class Queue(object):

    # Initialize a Queue
    def __init__(self, name):
        self.name = name
        self.waitingentities = [] # Ensure this is an instance attribute

    # Print a Queue (just its name and the entire list of waiting Entities)
    def __repr__(self):
        return self.name + ": " + str(self.waitingentities)

    # An Entity arrives at this Queue
    def ArriveatQueue(self, entity, current_sim_time):
        self.waitingentities.append(entity)
        entity.arrival_time_at_queue = current_sim_time # Record the time it entered the queue

    # An Entity leaves the Queue (and goes to processor)
    def LeaveQueue(self):
        if self.waitingentities:
            return self.waitingentities.pop(0) # Remove and return the first entity
        return None

class LLMProcessor(object):
    def __init__(self, name, fixed_overhead_c, time_per_token_a, batch_size):
        self.name = name
        self.fixed_overhead_c = fixed_overhead_c  # Fixed overhead in ms, applied once per batch
        self.time_per_token_a = time_per_token_a  # Time per token in ms/token
        self.batch_size = batch_size
        self.processing_batch = [] # List of entities in the current batch
        self.time_processing_ends = -1

    def __repr__(self):
        return f"{self.name}: {'Busy' if self.is_busy() else 'Idle'} (Batch Size: {len(self.processing_batch)}/{self.batch_size})"

    def is_busy(self):
        return len(self.processing_batch) > 0

    def start_processing(self, entities, current_sim_time):
        if self.is_busy():
            return False # Processor is already busy with a batch

        if not entities:
            return False # No entities to process

        self.processing_batch = entities
        total_p_tokens_in_batch = sum(e.p_token for e in entities)
        total_b_tokens_in_batch = sum(e.b_token for e in entities)

        # Total processing time for this batch: c + a * (sum(P_i) + sum(B_i))
        batch_processing_time = self.fixed_overhead_c + self.time_per_token_a * (total_p_tokens_in_batch + total_b_tokens_in_batch)

        self.time_processing_ends = current_sim_time + batch_processing_time

        for entity in entities:
            entity.start_processing_time = current_sim_time

        return True

    def finish_processing(self, current_sim_time):
        if self.is_busy() and current_sim_time >= self.time_processing_ends:
            completed_entities = self.processing_batch # All entities in the batch complete together
            for entity in completed_entities:
                entity.completion_time = self.time_processing_ends

            self.processing_batch = [] # Clear the batch
            self.time_processing_ends = -1
            return completed_entities # Return the list of completed entities
        return [] # Return empty list if no batch completed

class LLMSimulation(object):
    def __init__(self, fixed_overhead_c, time_per_token_a, arrival_rate_entities_per_ms, simulation_duration_ms, batch_size=1):
        self.fixed_overhead_c = fixed_overhead_c
        self.time_per_token_a = time_per_token_a
        self.arrival_rate_entities_per_ms = arrival_rate_entities_per_ms
        self.simulation_duration_ms = simulation_duration_ms
        self.batch_size = batch_size # New parameter

        self.queue = Queue("LLM Queue")
        # Pass c, a, and batch_size to the processor
        self.processor = LLMProcessor("LLM GPU", fixed_overhead_c, time_per_token_a, batch_size)

        self.current_sim_time = 0.0
        self.next_arrival_time = 0.0
        self.all_entities = []
        self.completed_entities = []

    def generate_next_arrival_time(self):
        # Exponential distribution for inter-arrival times
        # arrival_rate_entities_per_ms is lambda
        # 1/lambda is mean inter-arrival time
        mean_inter_arrival_time = 1.0 / self.arrival_rate_entities_per_ms
        inter_arrival_time = np.random.exponential(mean_inter_arrival_time)
        self.next_arrival_time = self.current_sim_time + inter_arrival_time

    def run_simulation(self):
        self.generate_next_arrival_time() # Schedule the first arrival

        while self.current_sim_time <= self.simulation_duration_ms or self.queue.waitingentities or self.processor.is_busy():
            # Determine the next event time
            next_event_time = float('inf')
            if self.current_sim_time < self.simulation_duration_ms:
                next_event_time = min(next_event_time, self.next_arrival_time)
            if self.processor.is_busy():
                next_event_time = min(next_event_time, self.processor.time_processing_ends)

            # If no more events, break (e.g., if simulation duration is reached and queues/processors are empty)
            if next_event_time == float('inf'):
                break

            # Advance simulation time to the next event
            self.current_sim_time = next_event_time

            # --- Event Handling ---

            # 1. Handle arrivals
            if self.current_sim_time >= self.next_arrival_time and self.current_sim_time <= self.simulation_duration_ms:
                new_entity = Entity(self.current_sim_time)
                self.all_entities.append(new_entity)
                self.queue.ArriveatQueue(new_entity, self.current_sim_time)
                # Schedule next arrival
                self.generate_next_arrival_time()

            # 2. Handle processor completion
            completed_batch = self.processor.finish_processing(self.current_sim_time)
            if completed_batch:
                self.completed_entities.extend(completed_batch) # Extend with the list of completed entities
                # print(f"[Time {self.current_sim_time:.2f}] Batch completed: {completed_batch}")

            # 3. Try to move entities from queue to processor
            if not self.processor.is_busy():
                entities_to_batch = []
                num_waiting = len(self.queue.waitingentities)

                # Condition to start a batch:
                # 1. Enough entities for a full batch, OR
                # 2. Not enough for a full batch, but simulation duration is passed AND there are no more future arrivals AND there are entities waiting
                can_start_full_batch = (num_waiting >= self.batch_size)
                can_start_partial_batch_at_end = (num_waiting > 0 and
                                                  self.current_sim_time >= self.simulation_duration_ms and
                                                  self.next_arrival_time > self.simulation_duration_ms)

                if can_start_full_batch or can_start_partial_batch_at_end:
                    # Determine how many entities to take for the batch
                    batch_count = self.batch_size if can_start_full_batch else num_waiting

                    for _ in range(batch_count):
                        entities_to_batch.append(self.queue.LeaveQueue())

                    if entities_to_batch:
                        self.processor.start_processing(entities_to_batch, self.current_sim_time)
                        # print(f"[Time {self.current_sim_time:.2f}] Started processing batch of {len(entities_to_batch)} entities.")

        print(f"Simulation finished at time {self.current_sim_time:.2f} ms.")
        print(f"Total entities generated: {len(self.all_entities)}")
        print(f"Total entities completed: {len(self.completed_entities)}")

        # Calculate and print metrics for completed entities
        if self.completed_entities:
            # New Metric 1: Average Time to First Token
            time_to_first_token_list = [(e.start_processing_time - e.arrival_time_at_system) for e in self.completed_entities]
            avg_time_to_first_token = np.mean(time_to_first_token_list)

            # New Metric 2: Throughput in tokens/second
            total_p_tokens = sum(e.p_token for e in self.completed_entities)
            total_b_tokens = sum(e.b_token for e in self.completed_entities)
            total_tokens_processed = total_p_tokens + total_b_tokens

            # Convert simulation duration from ms to seconds
            actual_sim_duration_seconds = self.current_sim_time / 1000.0
            throughput_tokens_per_second = total_tokens_processed / actual_sim_duration_seconds if actual_sim_duration_seconds > 0 else 0.0

            print(f"\nAverage Time to First Token: {avg_time_to_first_token:.2f} ms")
            print(f"Time Between Tokens (a): {self.time_per_token_a:.2f} ms/token")
            print(f"Throughput: {throughput_tokens_per_second:.2f} tokens/second")
        else:
            print("No entities completed during the simulation.")

fixed_overhead_c = 35.0  # ms (mid-range of 20-50 ms)
time_per_token_a = 0.3   # ms/token (mid-range of 0.1-0.5 ms/token)
arrival_rate_entities_per_ms = 0.01 # 0.01 entities per ms (1 entity per 100 ms)
simulation_duration_ms = 1000000.0 # 100 seconds simulation
batch_size = 10 # New parameter: Number of entities processed concurrently

# Create and run the simulation
sim = LLMSimulation(
    fixed_overhead_c=fixed_overhead_c,
    time_per_token_a=time_per_token_a,
    arrival_rate_entities_per_ms=arrival_rate_entities_per_ms,
    simulation_duration_ms=simulation_duration_ms,
    batch_size=batch_size
)
sim.run_simulation()